







-- Johdanto

Linkitetty lista on lähes aina taulukkoa (englanniksi array) tehottomampi. [lähde: never-linked-list] 

Keskusmuistista datan noutaminen kestää satoja kertoja pidempään kuin prosessorin nopeasta välimuistista. [lähde: 10-million] Koska linkitetty lista ei ota kantaa muistin sijoitteluun päätyy sen data mahdollisesti pitkin poikin muistia. Tällöin tietokone ei voi hyödyntää leveää muistikaistaansa monen listasolmun noutamiseen kerralla keskusmuistista, vaan ne on noudettava yksi kerrallaan.

Useimmat puurakenteet käyttävät linkitetyn listan kaltaista tapaa yhdistää solmut toisiinsa pointtereilla. [lähde? wikipedia?] Tässä tutkielmassa pyrin näyttämään, että pointtereista koostuva puurakentee on päihitettävissä taulukkomuotoisella tietorakenteella. 

Puurakenteilla, joissa solmuilla on vakio määrä lapsisolmuja (esimerkiksi binääripuu, quadtree, octree), voidaan tunnetusti käyttää taulukkoa datan säilömiseen. Tällöin data on esimerkiksi binääripuun tapauksessa yleensä järjestetty niin, että indeksissä i olevan solmun lapset ovat indekseissä i*2+1 ja i*2+2.

Käsittelemäni puurakenne (tästedes taulukkopuu) ei aseta rajaa solmun lasten määrälle.

Toisin kuin pointteripuussa taulukkopuussa solmut ovat yksiulotteisessa taulukossa. Solmut ovat järjestetty niin, että solmun perilliset ovat taulukossa välittömästi vanhempansa jälkeen kuten kaaviosta [AsciiArt] on nähtävissä. Järjestetyn hyötykuorman lisäksi ainoa tarvittava lisätieto on solmun syvyys.

<kuva>
ASCII ART PUUN RAKENTEESTA KUVANA
</kuva>

Tällä saavutetaan parempi cache-ystävällisyys ja tehokkaampi muistiväylän hyödyntäminen. Datan noutaminen keskusmuistista on noin 200 kertaa hitaampaa kuin prosessorin nopeimmasta välimuistista. [lähde?] <lista prosessorien muistihuti sykleistä?>

Keskusmuistista haetaan asioita muistiväylän kokoisissa paloissa. Tämän koko on tyypillisesti 256 - 512 bittiä. [VARMISTA & lähde?]

Kun puu on pakattu tiiviisti muistiin, voidaan se noutaa vähemmillä pyynnöillä kuin jos se olisi varattu pitkin poikin muistia. Koska keskusmuistista noudetaan dataa aina koko muistiväylän leveydeltä, on vain järkevää huolehtia siitä, että tästä datasta mahdollisimman suuri osa on jotain hyödyllistä. Muistiallokaattorit eivät tyypillisesti huolehdi tästi oma-alotteisesti. [lähde?]

Jotta haluttava data olisi tiiviisti muistissa, kannattaa se varata taulukkoon. Tätä tekniikkaa voi käyttää myös perinteisellä pointteripuulla alustamalla sen solmut ennaltavarattuun pooliin (= suomeksi varanto :/ ).

Toisin kuin perinteisessä pointteripuussa, ehdottamassani muistirakenteessa ei ole tarvetta säilöä minkäänlaisia lapsi- tai vanhempipointtereita. Tämä poistaa kaiken ylimäärisen datan arvojen välistä, mikä nopeuttaa puun noutamista muistista. Vertaa kaavio [structPointerTree] ja kaavio [structArrayTree].

<lähdekoodi>
struct PointerTreeNode
{
	Value               value;
	PointerTree*        parent;
	Array<PointerTree*> children;
};
struct PointerTree
{
	PointerTree root;
};
</lähdekoodi>
Kaavio structPointerTree. Perinteine pointteripuu C++:n kaltaisella kiellellä. Toisinaan pointteripuun solmussa on myös pointterit sisarsolmuihin.

<lähdekoodi>
struct ArrayTree
{
	Array<Value  > values;
	Array<Integer> depths;
};
</lähdekoodi>
Kaavio structArrayTree. ehdotettu muistirakenne C++:n kaltaisella kiellellä


Taulukkopuussa hyötykuorman lisäksi tallennamme toiseen taulukkoon numerona tiedon siitä, kuinka syvällä puussa kyseinen solmu on. Tietorakenteen topologia sisältää implisiittisesti kaiken muun tiedon vanhemmuus- ja sisaruussuhteista. Sääntönä taulukkopuun sisäiselle järjestykselle on, että jokaisen solmun jälkeläisten on oltavata taulukossa heti itse solmun jälkeen. Tällä saadaan aikaan se, että jokaisen solmun kannalta muut oleelliset solmut ovat muistissa tämän välittömässä läheisyydessä.

Koska syvyysarvot ovat tiiviissä taulukossa, voidaan esimerkiksi maksimisyvyyden hakemisessa hyödyntää rinnakkaisia SIMD-operaatioita, mikä nopeuttaa taulukon läpikäymistä huomattavasti. Testieni mukaan SIMD-toteutus suoriutuu maksimin hakemisesta kymmenesosassa tavallisen luupin suoritusajasta.

Huonona puolena taulukkopuun kannalta, jokainen sille suoritettu muokkausoperaatio on suoritettava siirtelemällä toisinaan isojakin muistikönttejä. Hypoteesini kuitenkin on, että cache-ystävällisyytensä ansiosta taulukkopuu on silti nopeampi kaikessa toiminnaassaan kuin pointteri puu, muuten paitsi aivan äärimmäisillä puu koilla. Suorituskykytestini osoittavat, että tämä pitäisi myös paikkansa.

Hyvänä puolena taulukkopuun suora läpikäyminen kulkee puun solmut syvyys-ensin järjestyksesä (depth-first). Tämä on hyödyllistä, koska monissa käyttötarkoituksissa puuta käydään läpi juuri tässä järjestyksesä. Esimerkiksi käyttöliittymäohjelmoinnissa widgettien ladonta, käyttäjän syötteen välitys ja piirto voidaan kaikki tehdä tässä järjestyksessä.

Tehokkuuden kannalta taulukkopuun tärkein hyvä puoli verrattuna pointteripuuhun on, että puussa vaeltaminen ei edellytä pointtereiden dereferointia. On tärkeä muistaa, että pointterin seuraaminen voi johtaa muistiin, joka ei ole prosessorin välimuistissa, mikä aiheuttaa niin kutsutun muistihudin (=cache miss). Muistihudista aiheutuvaa suorituskykymenetystä ei ole mahdollista optimoida pois compilereillä, joten ohjelmoijien on oltava valppaina muistiraktenteidensa kanssa.

Jos tietorakennetta kuten puuta käydään läpi paljon useammin kuin sitä muokataan, sen rakentamiseen liittyvät huonot puolet ja hidasteet ovat mitätön seikka verrattuna haussa esiintyviin hidasteisiin.





--Lisäys, poisto ja siirto operaatiot

Niissä pitää memmovettaa kamaa.

Jos on iso chunkki, tarvitsee joskus myös dynaamisesti varata muistia, ettei stack overflowaa.

Koodiesimerkkejä.






--Syvyys, etsintä ja leaf travel





--Transform2D esimerkki







--Cache rakenteet

Koska taulukkopuu on pohjimmiltaan vain taulukkomuotoista dataa, on siitä helppo tehdä cache-rakenteita, jotka auttavat sitä suoritumaan joissain tehtävissä nopeammin. Esimerkiksi cache-rakenne, jossa on samalla indeksillä kuin varsinaisessa taulukkopuussa solmun seuraavan sisarsolmun indeksi.

Cache-rakenteita on myös tehokas koota, käymällä taulukkopuu läpi takaperin ja tallentamalla kunkin syvyyden edellisen solmun numero tilapäiseen taulukkoon. Tämä arvo voidaan sitten sijottaa cache-rakenteeseen seuraavan solmun kohdalle. Tätä havainnollistetaan kaaviossa [makeCache].


<lähdekoodi>
void makeCache(NextSiblingCache cache, ArrayTree tree)
{
	// Taulukko jossa tilapäisesti säilytetään
	// jokaisen syvyyden edellisen solmun indeksi
	Array<Integer> previous;
	
	// Varaa tilaa taulukkoon jokaiselle syvyydelle
	// ja alusta taulukon jokainen arvo InvalidIndexiksi
	resize(previous, getDepth(tree));
	setValues(previous, InvalidIndex);
	
	Integer previousDepth = 0;
	
	// Käy taulukkopuu läpi takaperin tallentaen cacheen
	// edellisen sisaren arvo.
	for(Integer i = count; i-- > 0; )
	{
		// Tallenna edellinen samalla syvyydellä oleva solmu
		Integer depth = tree.depths[i];
		c[i] = previous[depth];
		previous[depth] = i;
		
		// Jos syvyys vähenee, edellinen arvo ei voi olla
		// enää kenenkään sisarsolmu.
		if(depth < previousDepth)
			previous[previousDepth] = InvalidIndex;
		previousDepth = depth;
	}
}
</lähdekoodi>
Kaavio makeCache. Esimerkki cache-rakenteen kokoamisesta. Tämä on mahdollista toteuttaa ilman dynaamista muistin varausta käymällä taulukkopuu läpi syvyyden mukaan osiin jaettuna.





Testausmetodologia

Toteutin sekä taulukkopuun että perinteisen pointteripuun, ja niiden muokkaukseen vaadittavat algoritmit C++:lla.

Kirjoitin testauskoodin, joka kasaa topologisesti identtiset puurakenteet kaikilla eri kokoonpanoilla.

* Taulukkopuu
* Taulukkopuu + cache
* Taulukkopuu + cache joka pitää joka kerta alustaa uusiksi
* Pointteripuu
* Pointteripuu jonka solmut varataan poolista

Testit ajetaan useilla eri määrillä solmuja, jotka vaihtelevat kymmenestä 300 000:een.

Jokaista testiä toistetaan useita kertoja, jotta satunnaiset suorituskykyheilahtelut saadaan suodatettua mahdollisimman tehokkaasti pois.

Käsiteltävien solmujen yhtenäisyyden säilyttämiseksi eri puissa, pointteripuussa haetaan relevantit solmut syvyys-ensin järjestyksessä (samassa johon taulukkopuu on järjestetty). Tämä hidastaa pointteripuu testejä yleisesti, mutta sen ei pitäisi vaikuta mittaustuloksiin koska ajastukset tehdään jokaiselle operaatiolla yksittäin kuten kaaviossa [testMove] näytetään. Tämä saattaa vaikuttaa testaustuloksiin positiivisesti, koska pointteripuun solmuja on jo valmiiksi prosessorin välimuistissa, kun testi alkaa.


<lähdekoodi>
void testMove(Integer childIndex, Integer parentIndex)
{
	// Valmistele testi
	PointerTreeNode* child  = getNthDescendant(tree.root, childIndex);
	PointerTreeNode* parent = getNthDescendant(tree.root, parentIndex);
	
	Time duration;
	
	// Tee testi
	{
		Time start = getPreciseTime();
		moveToParent(child, parent);
		Time end = getPreciseTime();
		duration = end - start;
	}
}
</lähdekoodi>
Kaavio testMove. Esimerkki testin toteutuksesta. Lapsisolmujen hakemiseen kuluva aika ei ole mukana testin suoritukseen laskettavassa ajassa.

Mielenkiinnon vuoksi testeissä otetaan myös talteen pointteripuiden solmujen hakemiseen kuluva aika. Periaatteessa tähän kuluva suoritusaika on O-notaatiolla ilmaistuna O(N), mutta koska jokainen pointterin hakeminen voi mahdollisesti aiheuttaa muistihudin, on N:n kerroin erittäin suuri.





Tulokset

Taulukkopuu 












Lähteet

[bloom] 1. Jih-Kwon Peir, Shih-Chang Lai, Shih-Lien Lu, Jared Stark, Konrad Lai - 2002 - Bloom filtering cache misses for accurate data speculation and prefetching

[pointer-chasing] 2. Gabriel Weisz, Joseph Melber, Yu Wang, Kermin Fleming, Eriko Nurvitadhi, and James C. Hoe - 2016 - A Study of Pointer-Chasing Performance on Shared-Memory Processor-FPGA Systems

[prefetching] 3. Amir Roth, Gurindar S. Sohi - ‎1999 - Effective Jump-Pointer Prefetching for Linked Data Structures

[never-linked-list] 4. Kjellkod's Blog - 2012 - Number crunching: Why you should never, ever, EVER use linked-list in your code again - https://kjellkod.wordpress.com/2012/02/25/why-you-should-never-ever-ever-use-linked-list-in-your-code-again/ [2016-07-24]

[10-million] 5. Todd Hoff - 2013 - The Secret to 10 Million Concurrent Connections - http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html [2016-07-24]

